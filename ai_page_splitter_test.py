#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½åˆ†é¡µæ¨¡å—ï¼ˆæµ‹è¯•ç‰ˆæœ¬ï¼‰
ä¸“é—¨ç”¨äºæµ‹è¯•ä¸¤æ¬¡è°ƒç”¨ç­–ç•¥çš„ç‹¬ç«‹ç‰ˆæœ¬
"""

import re
import json
import requests
from typing import Dict, List, Any, Optional, Tuple
from openai import OpenAI
from config import get_config
from logger import log_user_action

class AIPageSplitterTest:
    """AIæ™ºèƒ½åˆ†é¡µå¤„ç†å™¨ï¼ˆæµ‹è¯•ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–AIåˆ†é¡µå¤„ç†å™¨"""
        config = get_config()
        
        # æ ¹æ®å½“å‰é€‰æ‹©çš„æ¨¡å‹è·å–å¯¹åº”çš„é…ç½®
        model_info = config.get_model_info()
        
        # åˆå§‹åŒ–å¤šå¯†é’¥ç®¡ç†
        self._initialize_api_keys(model_info, config, api_key)
        
        self.base_url = model_info.get('base_url', config.openai_base_url)
        self.config = config
        
        # åˆ›å»ºæŒä¹…åŒ–sessionç”¨äºHTTPè¿æ¥å¤ç”¨
        self.session = requests.Session()
        
        # ç®€å•çš„å†…å­˜ç¼“å­˜
        self._cache = {}
        
        # å¯†é’¥è½®è¯¢ç´¢å¼•
        self._current_key_index = 0
        
    
    def _initialize_api_keys(self, model_info, config, api_key):
        """åˆå§‹åŒ–APIå¯†é’¥åˆ—è¡¨"""
        import os
        
        if api_key:
            self.api_keys = [api_key]
            return
        
        if model_info.get('api_provider') == 'Volces' and model_info.get('use_multiple_keys'):
            # ä»ç¯å¢ƒå˜é‡è·å–ç«å±±å¼•æ“å¯†é’¥ï¼ˆå¤šå¯†é’¥è´Ÿè½½å‡è¡¡ï¼‰
            self.api_keys = []
            for i in range(1, 6):  # æ”¯æŒ1-5ä¸ªå¯†é’¥
                key_name = f'ARK_API_KEY_{i}'
                key_value = os.getenv(key_name)
                if key_value:
                    self.api_keys.append(key_value)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·å¯†é’¥ï¼Œå°è¯•å•ä¸ªå¯†é’¥
            if not self.api_keys:
                single_key = os.getenv('ARK_API_KEY')
                if single_key:
                    self.api_keys = [single_key]
        elif model_info.get('api_provider') == 'Liai':
            # Liai APIå¤šå¯†é’¥è´Ÿè½½å‡è¡¡
            self.api_keys = []
            for i in range(1, 6):  # æ”¯æŒ1-5ä¸ªå¯†é’¥
                key_name = f'LIAI_API_KEY_{i}'
                key_value = os.getenv(key_name)
                if key_value:
                    self.api_keys.append(key_value)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·å¯†é’¥ï¼Œå°è¯•å•ä¸ªå¯†é’¥
            if not self.api_keys:
                single_key = os.getenv('LIAI_API_KEY')
                if single_key:
                    self.api_keys = [single_key]
        else:
            # å…¶ä»–APIä½¿ç”¨å•å¯†é’¥
            api_key_env = model_info.get('api_key_env')
            if api_key_env:
                key_value = os.getenv(api_key_env) or config.openai_api_key or ""
                if key_value:
                    self.api_keys = [key_value]
                else:
                    self.api_keys = []
            else:
                self.api_keys = [config.openai_api_key] if config.openai_api_key else []
        
        if not self.api_keys:
            raise ValueError("è¯·è®¾ç½®APIå¯†é’¥")
        
        print(f"åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨APIå¯†é’¥æ•°é‡: {len(self.api_keys)}")
    
    def _get_next_api_key(self):
        """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥ï¼ˆè½®è¯¢ï¼‰"""
        if not self.api_keys:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥")
        
        key = self.api_keys[self._current_key_index]
        self._current_key_index = (self._current_key_index + 1) % len(self.api_keys)
        return key
    
    def split_text_to_pages(self, user_text: str, target_pages: Optional[int] = None) -> Dict[str, Any]:
        """
        å°†ç”¨æˆ·æ–‡æœ¬æ™ºèƒ½åˆ†å‰²ä¸ºå¤šä¸ªPPTé¡µé¢ï¼ˆæµ‹è¯•ç‰ˆæœ¬ - å›ºå®šä½¿ç”¨ä¸¤æ¬¡è°ƒç”¨ç­–ç•¥ï¼‰
        
        Args:
            user_text: ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ–‡æœ¬
            target_pages: ç›®æ ‡é¡µé¢æ•°é‡ï¼ˆå¯é€‰ï¼Œç”±AIè‡ªåŠ¨åˆ¤æ–­ï¼‰
            
        Returns:
            Dict: åˆ†é¡µç»“æœï¼ŒåŒ…å«æ¯é¡µçš„å†…å®¹å’Œåˆ†æ
        """
        log_user_action("AIæ™ºèƒ½åˆ†é¡µæµ‹è¯•", f"æ–‡æœ¬é•¿åº¦: {len(user_text)}, ä¸¤æ¬¡è°ƒç”¨ç­–ç•¥")
        
        try:
            # å›ºå®šä½¿ç”¨ä¸¤æ¬¡è°ƒç”¨ç­–ç•¥
            return self._split_with_two_pass(user_text, target_pages)
            
        except Exception as e:
            print(f"AIåˆ†é¡µåˆ†æå¤±è´¥: {e}")
            raise e
    
    def _split_with_two_pass(self, user_text: str, target_pages: Optional[int]) -> Dict[str, Any]:
        """ä¸¤æ¬¡è°ƒç”¨åˆ†é¡µç­–ç•¥ï¼šç¬¬ä¸€æ¬¡æ³¨é‡é€»è¾‘æ€§ï¼Œç¬¬äºŒæ¬¡æ³¨é‡åˆ†é¡µæ•°"""
        print(f"ğŸ”„ å¼€å§‹ä¸¤æ¬¡è°ƒç”¨AIåˆ†é¡µç­–ç•¥ï¼Œç›®æ ‡é¡µæ•°: {target_pages}")
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šæ³¨é‡é€»è¾‘ç»“æ„ï¼Œä¸å¼ºåˆ¶é¡µæ•°
        print("ğŸ“ ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šåˆ†æå†…å®¹é€»è¾‘ç»“æ„...")
        first_system_prompt = self._build_logical_structure_prompt()
        first_content = self._call_api_with_prompt(first_system_prompt, user_text)
        first_result = self._parse_ai_response_without_ending(first_content, user_text)  # ä¸æ·»åŠ ç»“å°¾é¡µ
        
        print(f"âœ… ç¬¬ä¸€æ¬¡è°ƒç”¨å®Œæˆï¼Œç”Ÿæˆ {first_result['analysis']['total_pages']} é¡µ")
        
        # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šåŸºäºç¬¬ä¸€æ¬¡ç»“æœï¼Œè°ƒæ•´é¡µæ•°
        if target_pages:
            print(f"ğŸ¯ ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè°ƒæ•´é¡µæ•°è‡³ç›®æ ‡ {target_pages} é¡µ...")
        else:
            print(f"ğŸ¯ ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šä¼˜åŒ–é¡µæ•°ï¼ˆå½“å‰ {first_result['analysis']['total_pages']} é¡µï¼Œå‡å°‘è¿‡åº¦åˆ†é¡µï¼‰...")
        second_system_prompt = self._build_page_adjustment_prompt(target_pages)
        
        # å°†ç¬¬ä¸€æ¬¡çš„ç»“æœä½œä¸ºä¸Šä¸‹æ–‡ä¼ ç»™ç¬¬äºŒæ¬¡è°ƒç”¨
        first_result_text = self._format_first_result_for_second_call(first_result)
        second_content = self._call_api_with_prompt(second_system_prompt, first_result_text)
        second_result = self._parse_ai_response(second_content, user_text)
        
        print(f"âœ… ç¬¬äºŒæ¬¡è°ƒç”¨å®Œæˆï¼Œæœ€ç»ˆç”Ÿæˆ {second_result['analysis']['total_pages']} é¡µ")
        
        # æ ‡è®°ä¸ºä¸¤æ¬¡è°ƒç”¨ç»“æœ
        second_result['is_two_pass_result'] = True
        second_result['first_pass_pages'] = first_result['analysis']['total_pages'] + 1  # ç¬¬ä¸€æ¬¡é¡µæ•° + ç»“å°¾é¡µ
        second_result['final_pass_pages'] = second_result['analysis']['total_pages']  # ç¬¬äºŒæ¬¡é¡µæ•°å·²åŒ…å«ç»“å°¾é¡µ
        
        return second_result
    
    def _call_api_with_prompt(self, system_prompt: str, user_text: str) -> str:
        """æ ¹æ®é…ç½®è°ƒç”¨ç›¸åº”çš„API"""
        model_info = self.config.get_model_info()
        if model_info.get('request_format') == 'dify_compatible':
            # ä½¿ç”¨Liai APIæ ¼å¼
            return self._call_liai_api(system_prompt, user_text)
        elif model_info.get('request_format') == 'streaming_compatible':
            # ä½¿ç”¨ç«å±±å¼•æ“DeepSeek APIæ ¼å¼
            return self._call_deepseek_api(system_prompt, user_text)
        else:
            # æ ‡å‡†OpenAI APIæ ¼å¼
            request_timeout = 60
            actual_model = model_info.get('actual_model', self.config.ai_model)
            
            # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if not hasattr(self, 'client'):
                from openai import OpenAI
                self.client = OpenAI(
                    api_key=self._get_next_api_key(),
                    base_url=self.base_url,
                    timeout=request_timeout
                )
            
            response = self.client.chat.completions.create(
                model=actual_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=self.config.ai_temperature,
                stream=True,
                timeout=request_timeout
            )
            
            # æ”¶é›†æµå¼å“åº”å†…å®¹
            content = ""
            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    content += chunk.choices[0].delta.content
            
            return content.strip() if content else ""
    
    def _build_logical_structure_prompt(self) -> str:
        """æ„å»ºç¬¬ä¸€æ¬¡è°ƒç”¨çš„é€»è¾‘ç»“æ„åˆ†ææç¤ºï¼ˆä¸å¼ºåˆ¶é¡µæ•°ï¼‰"""
        return f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±PPTæ¶æ„å¸ˆã€‚è¯·æŒ‰ç…§ä»¥ä¸‹**ä¸¥æ ¼æµç¨‹**å°†æ–‡æœ¬è½¬åŒ–ä¸ºPPTåˆ†é¡µå¤§çº²ï¼š

**ç¬¬ä¸€æ­¥ï¼šå…¨å±€åˆ†æ**
- é¦–å…ˆï¼Œé€šè¯»å…¨æ–‡ï¼Œè¯†åˆ«å‡ºæ–‡æœ¬çš„**æ ¸å¿ƒé€»è¾‘ç»“æ„**ï¼ˆå¦‚ï¼šå¼•è¨€->é—®é¢˜åˆ†æ->æ•°æ®è®ºè¯->è§£å†³æ–¹æ¡ˆ->æ€»ç»“ï¼‰
- å°†æ•´ä¸ªæ–‡æœ¬åˆ’åˆ†ä¸ºå‡ ä¸ªä¸»è¦éƒ¨åˆ†

**ç¬¬äºŒæ­¥ï¼šé€éƒ¨åˆ†åˆ†é¡µ**
- å¯¹äº**æ¯ä¸€ä¸ªä¸»è¦éƒ¨åˆ†**ï¼Œæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
  1. **æå–æ ¸å¿ƒè®ºç‚¹**ï¼šæ‰¾å‡ºè¿™éƒ¨åˆ†è¦è¯æ˜çš„1ä¸ªæœ€ç»ˆè§‚ç‚¹
  2. **æ”¶é›†è®ºæ®**ï¼šå°†æ‰€æœ‰æ”¯æŒè¯¥è®ºç‚¹çš„æ®µè½ã€æ•°æ®å’Œè®ºæ®é›†åˆèµ·æ¥
  3. **åˆå¹¶æˆä¸€é¡µ**ï¼š**å°†ä¸Šè¿°æ‰€æœ‰å†…å®¹ï¼ˆæ ¸å¿ƒè®ºç‚¹+æ‰€æœ‰è®ºæ®ï¼‰å…±åŒä½œä¸ºä¸€é¡µPPTçš„æ–‡æœ¬å†…å®¹**ã€‚å³ä½¿å†…å®¹å¾ˆé•¿ï¼Œä¹Ÿå…ˆæ”¾åœ¨ä¸€èµ·
  4. **ä¿ç•™å®Œæ•´æ–‡æœ¬**ï¼šæ— è®ºæ€ä¹ˆåˆ†é¡µï¼Œæ¯ä¸€é¡µéƒ½å¿…é¡»åŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´ç”¨æˆ·åŸå§‹æ–‡æœ¬ï¼Œä¸èƒ½é—æ¼æˆ–æˆªæ–­

**ç¬¬ä¸‰æ­¥ï¼šæ‹†åˆ†ä¾‹å¤–è§„åˆ™**
- **ä»…åœ¨ä»¥ä¸‹æƒ…å†µä¸‹**ï¼Œæ‰å…è®¸å°†ä¸€é¡µå†…å®¹æ‹†åˆ†æˆå¤šé¡µï¼š
  a. åŒ…å«äº†**ä¸¤ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ ¸å¿ƒè®ºç‚¹**

**åˆ†é¡µç­–ç•¥ï¼š**
- **æ ‡é¢˜é¡µï¼ˆç¬¬1é¡µï¼‰**ï¼šPPTå°é¢é¡µï¼Œä¸å¯¹åº”ä»»ä½•åŸæ–‡å†…å®¹ï¼Œè‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜å’Œæ—¥æœŸ
- **ç›®å½•é¡µï¼ˆç¬¬2é¡µï¼‰**ï¼šAIæ ¹æ®å†…å®¹ç»“æ„ç”Ÿæˆå®Œæ•´ç›®å½•
- **å†…å®¹é¡µï¼ˆç¬¬3é¡µå¼€å§‹ï¼‰**ï¼šå¤„ç†æ‰€æœ‰åŸæ–‡å†…å®¹ï¼ŒæŒ‰é€»è¾‘ç»“æ„åˆ†é¡µ
- **ç»“å°¾é¡µ**ï¼šä¸ç”Ÿæˆç»“å°¾é¡µï¼ˆä½¿ç”¨é¢„è®¾æ¨¡æ¿ï¼‰

**æ ‡é¢˜é¡µå¤„ç†è§„åˆ™ï¼š**
- æ ‡é¢˜é¡µæ˜¯PPTçš„å°é¢ï¼Œç”Ÿæˆåˆé€‚çš„PPTæ ‡é¢˜
- è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜ï¼ˆåŸºäºå†…å®¹ä¸»é¢˜ï¼‰
- original_text_segmentä¸titleç›¸åŒï¼ŒåŒ…å«PPTæ ‡é¢˜
- æ‰€æœ‰åŸæ–‡å†…å®¹éƒ½ä»ç¬¬2é¡µï¼ˆç›®å½•ï¼‰å’Œç¬¬3é¡µå¼€å§‹å¤„ç†

**é¡µé¢ç±»å‹è¯´æ˜ï¼š**
- `title`: æ ‡é¢˜é¡µï¼Œä»…åŒ…å«æ–‡æ¡£æ ‡é¢˜å’Œæ—¥æœŸ
- `table_of_contents`: ç›®å½•é¡µï¼Œå¿…é¡»åŒ…å«å„ç« èŠ‚æ ‡é¢˜ï¼ˆä¸å«é¡µç ï¼‰
- `content`: å†…å®¹é¡µï¼Œå…·ä½“çš„è¦ç‚¹å’Œè¯¦ç»†å†…å®¹ï¼ˆåˆ†é¡µé‡ç‚¹ï¼‰

**å­—æ®µè¦æ±‚ï¼š**
pageså­—æ®µé‡Œåªéœ€è¦åŒ…å«ï¼špage_number/page_type/title/original_text_segmentå­—æ®µ
- **titleå­—æ®µ**ï¼šå¿…é¡»å‡†ç¡®æ¦‚æ‹¬è¯¥é¡µå†…å®¹ï¼ˆç”¨äºç”Ÿæˆç›®å½•ï¼‰
- **original_text_segmentå­—æ®µæœ€é‡è¦**ï¼šå¿…é¡»åŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´åŸæ–‡ç‰‡æ®µï¼Œä¸èƒ½é—æ¼æˆ–æˆªæ–­

**å…³é”®æ³¨æ„äº‹é¡¹ï¼š**
- **æ ‡é¢˜é¡µoriginal_text_segment**ï¼šä¸titleç›¸åŒï¼ŒåŒ…å«PPTæ ‡é¢˜
- **ç›®å½•é¡µoriginal_text_segment**ï¼šåŒ…å«å„ç« èŠ‚æ ‡é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡é¢˜
- **å†…å®¹é¡µoriginal_text_segment**ï¼šåŒ…å«è¯¥é¡µé¢å¯¹åº”çš„æ‰€æœ‰åŸæ–‡å†…å®¹ï¼Œç¡®ä¿å®Œæ•´æ€§
- ä¸è¦ç”Ÿæˆç»“å°¾é¡µï¼Œç³»ç»Ÿå°†ä½¿ç”¨é¢„è®¾çš„å›ºå®šç»“å°¾é¡µæ¨¡æ¿

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

```json
[
  {{{{
    "page_number": 1,
    "page_type": "title",
    "title": "PPTæ ‡é¢˜ï¼ˆåŸºäºå†…å®¹ä¸»é¢˜ç”Ÿæˆï¼‰",
    "original_text_segment": "PPTæ ‡é¢˜ï¼ˆåŸºäºå†…å®¹ä¸»é¢˜ç”Ÿæˆï¼‰"
  }}}},
  {{{{
    "page_number": 2,
    "page_type": "table_of_contents",
    "title": "ç›®å½•",
    "original_text_segment": "ä¸»é¢˜ä¸€\nä¸»é¢˜äºŒ\nä¸»é¢˜ä¸‰"
  }}}},
  {{{{
    "page_number": 3,
    "page_type": "content",
    "title": "ä¸»é¢˜ä¸€æ ‡é¢˜",
    "original_text_segment": "å®Œæ•´çš„ä¸»é¢˜ä¸€å†…å®¹..."
  }}}}
]
```

åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

    def _build_page_adjustment_prompt(self, target_pages: Optional[int]) -> str:
        """æ„å»ºç¬¬äºŒæ¬¡è°ƒç”¨çš„é¡µæ•°è°ƒæ•´æç¤º"""
        if target_pages:
            # æœ‰æŒ‡å®šç›®æ ‡é¡µæ•°ï¼šç²¾ç¡®è°ƒæ•´
            ai_pages = target_pages - 1  # AIç”Ÿæˆé¡µæ•° = æ€»é¡µæ•° - ç»“å°¾é¡µ
            return f"""ä½ æ˜¯PPTé¡µæ•°ç²¾ç¡®è°ƒæ•´ä¸“å®¶ã€‚ç”¨æˆ·æ˜ç¡®è¦æ±‚PPTæ€»å…±{target_pages}é¡µï¼Œä½ å¿…é¡»ä¸¥æ ¼æ»¡è¶³è¿™ä¸ªéœ€æ±‚ã€‚

ã€ä¸¥æ ¼è¦æ±‚ã€‘ä½ åªéœ€ç”Ÿæˆ{ai_pages}é¡µå†…å®¹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ ç¬¬{target_pages}é¡µç»“å°¾é¡µï¼

**PPTé¡µæ•°è°ƒæ•´ä»»åŠ¡ï¼š**
åŸºäºç¬¬ä¸€æ¬¡AIåˆ†æç»“æœï¼Œé‡æ–°ç»„ç»‡PPTå†…å®¹ä»¥ç²¾ç¡®æ»¡è¶³ç”¨æˆ·çš„{target_pages}é¡µè¦æ±‚ï¼š

**é¡µé¢åˆ†é…ï¼š**
- ä½ è´Ÿè´£ç”Ÿæˆï¼š{ai_pages}é¡µå†…å®¹ï¼ˆç¬¬1é¡µåˆ°ç¬¬{ai_pages}é¡µï¼‰
- ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ï¼šç¬¬{target_pages}é¡µç»“å°¾é¡µ
- æœ€ç»ˆPPTæ€»é¡µæ•°ï¼š{target_pages}é¡µï¼ˆå®Œå…¨ç¬¦åˆç”¨æˆ·è¦æ±‚ï¼‰

**è°ƒæ•´ç­–ç•¥ï¼š**
- ä¿æŒæ ‡é¢˜é¡µ(ç¬¬1é¡µ)å’Œç›®å½•é¡µ(ç¬¬2é¡µ)ä¸å˜
- å†…å®¹é¡µèŒƒå›´ï¼šç¬¬3é¡µåˆ°ç¬¬{ai_pages}é¡µ
- é€šè¿‡åˆå¹¶æˆ–æ‹†åˆ†å†…å®¹é¡µæ¥ç²¾ç¡®è¾¾åˆ°{ai_pages}é¡µ
- ç¡®ä¿æ¯é¡µå†…å®¹å……å®ï¼Œç¬¦åˆPPTå±•ç¤ºæ ‡å‡†
- **ã€ä¸¥æ ¼300å­—é™åˆ¶ã€‘é™¤äº†æ ‡é¢˜é¡µã€ç›®å½•é¡µå’Œç»“å°¾é¡µï¼Œæ‰€æœ‰å†…å®¹é¡µçš„original_text_segmentå¿…é¡»åŒ…å«è‡³å°‘300å­—åŸå§‹æ–‡æœ¬ï¼Œä¸è¶³300å­—çš„é¡µé¢å¿…é¡»ä¸ç›¸é‚»é¡µé¢åˆå¹¶**

**å­—æ®µè¦æ±‚ï¼š**
pageså­—æ®µé‡Œåªéœ€è¦åŒ…å«ï¼špage_number/page_type/title/original_text_segmentå­—æ®µ
- **titleå­—æ®µ**ï¼šå¿…é¡»å‡†ç¡®æ¦‚æ‹¬è¯¥é¡µå†…å®¹
- **original_text_segmentå­—æ®µ**ï¼šåŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´åŸæ–‡ç‰‡æ®µï¼Œä¸èƒ½é—æ¼

ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼Œå¿…é¡»ç”Ÿæˆ{ai_pages}é¡µï¼š

```json
[
  {{{{
    "page_number": 1,
    "page_type": "title",
    "title": "PPTæ ‡é¢˜",
    "original_text_segment": "PPTæ ‡é¢˜"
  }}}},
  {{{{
    "page_number": 2,
    "page_type": "table_of_contents",
    "title": "ç›®å½•",
    "original_text_segment": "ç›®å½•å†…å®¹"
  }}}},
  {{{{
    "page_number": 3,
    "page_type": "content",
    "title": "å†…å®¹é¡µæ ‡é¢˜",
    "original_text_segment": "é¡µé¢å†…å®¹"
  }}}}
]
```

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
        else:
            # æ— æŒ‡å®šç›®æ ‡é¡µæ•°ï¼šä¼˜åŒ–å‡å°‘é¡µæ•°
            return f"""ä½ æ˜¯PPTå†…å®¹ä¼˜åŒ–ä¸“å®¶ã€‚åŸºäºç¬¬ä¸€æ¬¡AIåˆ†æç»“æœï¼Œä¼˜åŒ–PPTé¡µæ•°åˆ†é…ï¼Œè§£å†³è¿‡åº¦åˆ†é¡µé—®é¢˜ã€‚

ã€PPTåˆ†é¡µä¼˜åŒ–ä»»åŠ¡ã€‘
PPTåˆ¶ä½œä¸­ï¼ŒAIå®¹æ˜“è¿‡åº¦åˆ†é¡µå¯¼è‡´é¡µé¢å†…å®¹ç¨€è–„ã€‚ä½ éœ€è¦é€šè¿‡åˆå¹¶ç›¸å…³ä¸»é¢˜çš„å†…å®¹é¡µæ¥ä¼˜åŒ–é¡µæ•°ï¼š

**åˆ†é¡µåŸåˆ™ï¼š**
- ä¿æŒæ ‡é¢˜é¡µ(ç¬¬1é¡µ)å’Œç›®å½•é¡µ(ç¬¬2é¡µ)ä¸å˜
- åˆå¹¶é€»è¾‘ç›¸å…³çš„å†…å®¹é¡µï¼ˆå¦‚"äº§å“ä»‹ç»"+"äº§å“ç‰¹ç‚¹"åˆå¹¶ä¸ºä¸€é¡µï¼‰
- ç¡®ä¿æ¯é¡µå†…å®¹å……å®ï¼Œé¿å…å†…å®¹è¿‡å°‘æˆ–è¿‡å¤š
- ä¼˜åŒ–åçš„AIç”Ÿæˆé¡µæ•°åº”æ¯”ç¬¬ä¸€æ¬¡ç»“æœæ›´å°‘ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ ç»“å°¾é¡µï¼‰
- **ã€ä¸¥æ ¼300å­—é™åˆ¶ã€‘é™¤äº†æ ‡é¢˜é¡µã€ç›®å½•é¡µå’Œç»“å°¾é¡µï¼Œæ‰€æœ‰å†…å®¹é¡µçš„original_text_segmentå¿…é¡»åŒ…å«è‡³å°‘300å­—åŸå§‹æ–‡æœ¬ï¼Œä¸è¶³300å­—çš„é¡µé¢å¿…é¡»ä¸ç›¸é‚»é¡µé¢åˆå¹¶**

**å­—æ®µè¦æ±‚ï¼š**
pageså­—æ®µé‡Œåªéœ€è¦åŒ…å«ï¼špage_number/page_type/title/original_text_segmentå­—æ®µ
- **titleå­—æ®µ**ï¼šå¿…é¡»å‡†ç¡®æ¦‚æ‹¬è¯¥é¡µå†…å®¹
- **original_text_segmentå­—æ®µ**ï¼šåŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´åŸæ–‡ç‰‡æ®µï¼Œä¸èƒ½é—æ¼

ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼š

```json
[
  {{{{
    "page_number": 1,
    "page_type": "title",
    "title": "PPTæ ‡é¢˜",
    "original_text_segment": "PPTæ ‡é¢˜"
  }}}},
  {{{{
    "page_number": 2,
    "page_type": "table_of_contents",
    "title": "ç›®å½•",
    "original_text_segment": "ç›®å½•å†…å®¹"
  }}}},
  {{{{
    "page_number": 3,
    "page_type": "content",
    "title": "å†…å®¹é¡µæ ‡é¢˜",
    "original_text_segment": "é¡µé¢å†…å®¹"
  }}}}
]
```

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

    def _format_first_result_for_second_call(self, first_result: Dict[str, Any]) -> str:
        """å°†ç¬¬ä¸€æ¬¡è°ƒç”¨ç»“æœæ ¼å¼åŒ–ä¸ºç¬¬äºŒæ¬¡è°ƒç”¨çš„è¾“å…¥"""
        formatted_text = "ã€ç¬¬ä¸€æ¬¡AIåˆ†æç»“æœã€‘\n\n"
        
        # æ·»åŠ åˆ†æä¿¡æ¯
        analysis = first_result.get('analysis', {})
        formatted_text += f"åŸå§‹åˆ†æï¼šæ€»é¡µæ•°{analysis.get('total_pages', 0)}é¡µï¼Œ{analysis.get('split_strategy', 'æœªçŸ¥ç­–ç•¥')}\n\n"
        
        # æ·»åŠ æ¯é¡µçš„è¯¦ç»†å†…å®¹
        pages = first_result.get('pages', [])
        formatted_text += "ã€é¡µé¢è¯¦æƒ…ã€‘\n"
        for page in pages:
            page_num = page.get('page_number', 0)
            page_type = page.get('page_type', 'content')
            title = page.get('title', 'æ— æ ‡é¢˜')
            original_text = page.get('original_text_segment', '')
            
            formatted_text += f"\nç¬¬{page_num}é¡µ ({page_type}): {title}\n"
            formatted_text += f"å†…å®¹: {original_text}\n"
            formatted_text += "---\n"
        
        # æ·»åŠ åŸå§‹æ–‡æœ¬
        formatted_text += f"\nã€åŸå§‹æ–‡æœ¬ã€‘\n{first_result.get('original_text', '')}"
        
        return formatted_text

    def _call_liai_api(self, system_prompt: str, user_text: str) -> str:
        """è°ƒç”¨Liai APIï¼ˆæ”¯æŒå¤šå¯†é’¥è´Ÿè½½å‡è¡¡ï¼‰"""
        model_info = self.config.get_model_info()
        base_url = model_info.get('base_url', '')
        endpoint = model_info.get('chat_endpoint', '/chat-messages')
        
        url = base_url + endpoint
        
        # æ„å»ºLiai APIè¯·æ±‚æ ¼å¼
        combined_query = f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_text}"
        
        payload = {
            "inputs": {},
            "query": combined_query,
            "response_mode": "streaming",  # æ”¹ä¸ºstreamingæ¨¡å¼æå‡å“åº”é€Ÿåº¦
            "conversation_id": "",
            "user": "ai-ppt-user",
            "files": []
        }
        
        # å°è¯•æ‰€æœ‰å¯ç”¨å¯†é’¥
        last_exception = None
        for attempt in range(len(self.api_keys)):
            current_api_key = self._get_next_api_key()
            
            headers = {
                'Authorization': f'Bearer {current_api_key}',
                'Content-Type': 'application/json',
                'Connection': 'keep-alive'  # ä¿æŒè¿æ¥
            }
            
            try:
                print(f"å°è¯•ä½¿ç”¨Liai APIå¯†é’¥ {attempt + 1}/{len(self.api_keys)} (æœ«å°¾: ...{current_api_key[-8:]})")
                
                # ä½¿ç”¨æŒä¹…åŒ–ä¼šè¯å¤ç”¨è¿æ¥ï¼Œå¢åŠ è¶…æ—¶å¤„ç†
                response = self.session.post(url, headers=headers, json=payload, timeout=120, stream=True)
                response.raise_for_status()
                
                # å¤„ç†streamingå“åº”ï¼Œç‰¹åˆ«å¤„ç†é˜¿é‡Œäº‘APIçš„keep-alive
                content = ""
                for line in response.iter_lines():
                    if line:
                        try:
                            line_text = line.decode('utf-8').strip()
                            # å¿½ç•¥é˜¿é‡Œäº‘çš„keep-aliveæ³¨é‡Š
                            if line_text == ': keep-alive' or line_text == '':
                                continue
                            if line_text.startswith('data: '):
                                json_str = line_text[6:]  # å»æ‰'data: 'å‰ç¼€
                                if json_str.strip() == '[DONE]':
                                    break
                                data = json.loads(json_str)
                                if 'answer' in data:
                                    content += data['answer']
                                elif 'data' in data and 'answer' in data['data']:
                                    content += data['data']['answer']
                        except (json.JSONDecodeError, UnicodeDecodeError):
                            continue
                
                # å¦‚æœstreamingå¤±è´¥ï¼Œå°è¯•ä½œä¸ºæ™®é€šJSONå¤„ç†
                if not content:
                    try:
                        result = response.json()
                        content = result.get('answer', '') or result.get('data', {}).get('answer', '')
                    except:
                        pass
                
                # æˆåŠŸè·å–å†…å®¹ï¼Œè¿”å›ç»“æœ
                if content.strip():
                    print(f"âœ… Liai APIå¯†é’¥ ...{current_api_key[-8:]} è°ƒç”¨æˆåŠŸ")
                    return content.strip()
                else:
                    raise Exception("APIè¿”å›ç©ºå†…å®¹")
                    
            except Exception as e:
                last_exception = e
                print(f"âŒ Liai APIå¯†é’¥ ...{current_api_key[-8:]} è°ƒç”¨å¤±è´¥: {e}")
                
                # å¦‚æœè¿˜æœ‰å…¶ä»–å¯†é’¥å¯ä»¥å°è¯•ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                if attempt < len(self.api_keys) - 1:
                    print(f"â³ å°è¯•ä¸‹ä¸€ä¸ªLiai APIå¯†é’¥...")
                    continue
        
        # æ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥äº†
        print(f"âŒ æ‰€æœ‰{len(self.api_keys)}ä¸ªLiai APIå¯†é’¥éƒ½å¤±è´¥äº†")
        raise last_exception or Exception("æ‰€æœ‰Liai APIå¯†é’¥è°ƒç”¨å¤±è´¥")
    
    def _call_deepseek_api(self, system_prompt: str, user_text: str) -> str:
        """è°ƒç”¨DeepSeek APIï¼ˆå¸¦æ•…éšœè½¬ç§»çš„å¤šå¯†é’¥è´Ÿè½½å‡è¡¡ï¼‰"""
        model_info = self.config.get_model_info()
        
        # è·å–å®é™…æ¨¡å‹åç§°å’Œé¢å¤–å¤´éƒ¨
        actual_model = model_info.get('actual_model', 'deepseek-v3-250324')
        extra_headers = model_info.get('extra_headers', {})
        
        # å°è¯•æ‰€æœ‰å¯ç”¨å¯†é’¥
        last_exception = None
        for attempt in range(len(self.api_keys)):
            current_api_key = self._get_next_api_key()
            
            try:
                # ä¸ºå½“å‰å¯†é’¥åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
                temp_client = OpenAI(
                    api_key=current_api_key,
                    base_url=self.base_url,
                    timeout=120
                )
                
                print(f"å°è¯•ä½¿ç”¨APIå¯†é’¥ {attempt + 1}/{len(self.api_keys)} (æœ«å°¾: ...{current_api_key[-8:]})")
                
                # ä½¿ç”¨æŒä¹…åŒ–ä¼šè¯å¤ç”¨è¿æ¥ï¼Œç±»ä¼¼Liaiçš„å¤„ç†æ–¹å¼
                response = temp_client.chat.completions.create(
                    model=actual_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_text}
                    ],
                    temperature=self.config.ai_temperature,
                    stream=True,  # ä½¿ç”¨æµå¼å“åº”ï¼Œç±»ä¼¼Liai
                    extra_headers=extra_headers,
                    extra_body={},  # OpenRouterå…¼å®¹
                    timeout=120  # ä¸Liaiç›¸åŒçš„è¶…æ—¶æ—¶é—´
                )
                
                # å¤„ç†streamingå“åº”ï¼Œç±»ä¼¼Liaiçš„é€è¡Œå¤„ç†
                content = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                        chunk_content = chunk.choices[0].delta.content
                        if chunk_content:
                            content += chunk_content
                
                result_content = content.strip() if content else ""
                print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œä½¿ç”¨å¯†é’¥: ...{current_api_key[-8:]}")
                return result_content
                
            except Exception as e:
                last_exception = e
                print(f"âŒ APIå¯†é’¥ ...{current_api_key[-8:]} è°ƒç”¨å¤±è´¥: {e}")
                
                # å¦‚æœè¿˜æœ‰å…¶ä»–å¯†é’¥å¯ä»¥å°è¯•ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                if attempt < len(self.api_keys) - 1:
                    print(f"â³ å°è¯•ä¸‹ä¸€ä¸ªAPIå¯†é’¥...")
                    continue
        
        # æ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥äº†
        print(f"âŒ æ‰€æœ‰{len(self.api_keys)}ä¸ªOpenRouter APIå¯†é’¥éƒ½å¤±è´¥äº†")
        raise last_exception or Exception("æ‰€æœ‰OpenRouter APIå¯†é’¥è°ƒç”¨å¤±è´¥")
    
    def _parse_ai_response_without_ending(self, content: str, user_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº”ç»“æœï¼ˆä¸æ·»åŠ ç»“å°¾é¡µï¼‰"""
        result = self._parse_ai_response_base(content, user_text)
        return result
    
    def _parse_ai_response(self, content: str, user_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº”ç»“æœï¼ˆæ·»åŠ ç»“å°¾é¡µï¼‰"""
        result = self._parse_ai_response_base(content, user_text)
        
        # æ·»åŠ å›ºå®šçš„ç»“å°¾é¡µ
        self._add_ending_page(result)
        
        return result
    
    def _parse_ai_response_base(self, content: str, user_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº”ç»“æœçš„åŸºç¡€æ–¹æ³•"""
        try:
            # æ£€æŸ¥è¿”å›å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content or not content.strip():
                error_detail = f"AIè¿”å›å†…å®¹ä¸ºç©ºã€‚åŸå§‹å†…å®¹: '{content}'"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            # æå–JSONå†…å®¹ï¼ˆæ”¯æŒå¯¹è±¡{}å’Œæ•°ç»„[]ï¼‰
            json_match = re.search(r'```(?:json)?\s*([{\[].*?[}\]])\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
                json_str = content.strip()
            
            if not json_str or not json_str.strip():
                error_detail = "æå–çš„JSONå­—ç¬¦ä¸²ä¸ºç©º"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            # æ£€æŸ¥JSONæ˜¯å¦è¢«æˆªæ–­
            if json_str.strip().endswith(',"page_nu') or not json_str.strip().endswith((']', '}')):
                error_detail = f"JSONå“åº”è¢«æˆªæ–­ï¼Œå¯èƒ½æ˜¯tokené™åˆ¶å¯¼è‡´ã€‚JSONæœ«å°¾: ...{json_str[-50:]}"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            # è§£æJSON
            parsed_data = json.loads(json_str)
            
            # å¦‚æœè¿”å›çš„æ˜¯æ•°ç»„ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            if isinstance(parsed_data, list):
                result = {
                    'pages': parsed_data,
                    'analysis': {
                        'total_pages': len(parsed_data),
                        'content_type': 'è‡ªåŠ¨ç”Ÿæˆ',
                        'split_strategy': 'æ™ºèƒ½åˆ†é¡µ'
                    }
                }
            else:
                result = parsed_data
            
            # éªŒè¯ç»“æœæ ¼å¼
            validation_result = self._validate_split_result(result)
            if not validation_result['is_valid']:
                error_detail = f"AIè¿”å›çš„JSONæ ¼å¼ä¸ç¬¦åˆè¦æ±‚: {validation_result['error']}"
                print(f"âŒ {error_detail}")
                print(f"ğŸ” JSONå†…å®¹: {json.dumps(result, ensure_ascii=False, indent=2)[:1000]}...")
                raise ValueError(error_detail)
            
            result['success'] = True
            result['original_text'] = user_text
            
            return result
                
        except json.JSONDecodeError as e:
            json_str_safe = json_str[:500] if 'json_str' in locals() else 'æœªè·å–åˆ°'
            error_msg = f"JSONè§£æå¤±è´¥: {e}\nå°è¯•è§£æçš„å†…å®¹: {json_str_safe}"
            print(f"âŒ {error_msg}")
            raise ValueError(error_msg)
        except Exception as e:
            content_safe = content[:500] if content else 'N/A'
            error_msg = f"AIåˆ†é¡µè§£æå¤±è´¥: {e}\nåŸå§‹AIè¿”å›å†…å®¹: {content_safe}..."
            print(f"âŒ {error_msg}")
            raise e
    
    def _validate_split_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯åˆ†é¡µç»“æœçš„æ ¼å¼"""
        try:
            # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
            if 'analysis' not in result:
                return {'is_valid': False, 'error': 'ç¼ºå°‘analysiså­—æ®µ'}
            if 'pages' not in result:
                return {'is_valid': False, 'error': 'ç¼ºå°‘pageså­—æ®µ'}
            
            analysis = result['analysis']
            pages = result['pages']
            
            # æ£€æŸ¥analysiså­—æ®µ
            required_analysis_fields = ['total_pages', 'content_type', 'split_strategy']
            for field in required_analysis_fields:
                if field not in analysis:
                    return {'is_valid': False, 'error': f'analysisç¼ºå°‘å­—æ®µ: {field}'}
            
            # æ£€æŸ¥pagesæ•°ç»„
            if not isinstance(pages, list):
                return {'is_valid': False, 'error': 'pagesä¸æ˜¯æ•°ç»„ç±»å‹'}
            if len(pages) == 0:
                return {'is_valid': False, 'error': 'pagesæ•°ç»„ä¸ºç©º'}
            
            # æ£€æŸ¥æ¯ä¸ªé¡µé¢çš„å­—æ®µ
            required_page_fields = ['page_number', 'page_type', 'title', 'original_text_segment']
            for i, page in enumerate(pages):
                for field in required_page_fields:
                    if field not in page:
                        return {'is_valid': False, 'error': f'ç¬¬{i+1}ä¸ªé¡µé¢ç¼ºå°‘å­—æ®µ: {field}'}
                
                # æ£€æŸ¥original_text_segmentæ˜¯å­—ç¬¦ä¸²
                if not isinstance(page['original_text_segment'], str):
                    return {'is_valid': False, 'error': f'ç¬¬{i+1}ä¸ªé¡µé¢çš„original_text_segmentä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹'}
            
            return {'is_valid': True, 'error': None}
            
        except Exception as e:
            return {'is_valid': False, 'error': f'éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}'}
    
    def _add_ending_page(self, result: Dict[str, Any]) -> None:
        """æ·»åŠ å›ºå®šçš„ç»“å°¾é¡µ"""
        import os
        
        pages = result.get('pages', [])
        if not pages:
            return
        
        # è®¡ç®—ç»“å°¾é¡µçš„é¡µç 
        ending_page_number = len(pages) + 1
        
        # æ·»åŠ ç»“å°¾é¡µä¿¡æ¯
        ending_page = {
            "page_number": ending_page_number,
            "page_type": "ending",
            "title": "è°¢è°¢è§‚çœ‹",
            "original_text_segment": "",
            "template_path": os.path.join("templates", "ending_slides.pptx"),
            "is_fixed_template": True,
            "skip_dify_api": True  # æ ‡è®°ä¸ºè·³è¿‡Dify APIè°ƒç”¨
        }
        
        pages.append(ending_page)
        
        # æ›´æ–°æ€»é¡µæ•°
        if 'analysis' in result:
            result['analysis']['total_pages'] = len(pages)
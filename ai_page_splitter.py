#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½åˆ†é¡µæ¨¡å—
å°†ç”¨æˆ·è¾“å…¥çš„é•¿æ–‡æœ¬æ™ºèƒ½åˆ†å‰²ä¸ºé€‚åˆPPTå±•ç¤ºçš„å¤šä¸ªé¡µé¢
"""

import re
import json
import requests
from typing import Dict, List, Any, Optional, Tuple
from openai import OpenAI
from config import get_config
from logger import log_user_action

class AIPageSplitter:
    """AIæ™ºèƒ½åˆ†é¡µå¤„ç†å™¨"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–AIåˆ†é¡µå¤„ç†å™¨"""
        config = get_config()
        
        # æ ¹æ®å½“å‰é€‰æ‹©çš„æ¨¡å‹è·å–å¯¹åº”çš„é…ç½®
        model_info = config.get_model_info()
        
        # åˆå§‹åŒ–å¤šå¯†é’¥ç®¡ç†
        self._initialize_api_keys(model_info, config, api_key)
        
        self.base_url = model_info.get('base_url', config.openai_base_url)
        self.config = config
        
        # åˆ›å»ºæŒä¹…åŒ–sessionç”¨äºHTTPè¿æ¥å¤ç”¨
        self.session = requests.Session()
        
        # ç®€å•çš„å†…å­˜ç¼“å­˜
        self._cache = {}
        
        # å¯†é’¥è½®è¯¢ç´¢å¼•
        self._current_key_index = 0
        
    
    def _initialize_api_keys(self, model_info, config, api_key):
        """åˆå§‹åŒ–APIå¯†é’¥åˆ—è¡¨"""
        import os
        
        if api_key:
            self.api_keys = [api_key]
            return
        
        if model_info.get('api_provider') == 'OpenRouter':
            # ä»ç¯å¢ƒå˜é‡è·å–OpenRouterå¯†é’¥ï¼ˆç”¨æˆ·è‡ªå®šä¹‰ï¼‰
            self.api_keys = []
            for i in range(1, 6):  # æ”¯æŒ1-5ä¸ªå¯†é’¥
                key_name = f'OPENROUTER_API_KEY_{i}'
                key_value = os.getenv(key_name)
                if key_value:
                    self.api_keys.append(key_value)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·å¯†é’¥ï¼Œå°è¯•å•ä¸ªå¯†é’¥
            if not self.api_keys:
                single_key = os.getenv('OPENROUTER_API_KEY')
                if single_key:
                    self.api_keys = [single_key]
        elif model_info.get('api_provider') == 'Volces' and model_info.get('use_multiple_keys'):
            # ä»ç¯å¢ƒå˜é‡è·å–ç«å±±å¼•æ“å¯†é’¥ï¼ˆå¤šå¯†é’¥è´Ÿè½½å‡è¡¡ï¼‰
            self.api_keys = []
            for i in range(1, 6):  # æ”¯æŒ1-5ä¸ªå¯†é’¥
                key_name = f'ARK_API_KEY_{i}'
                key_value = os.getenv(key_name)
                if key_value:
                    self.api_keys.append(key_value)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·å¯†é’¥ï¼Œå°è¯•å•ä¸ªå¯†é’¥
            if not self.api_keys:
                single_key = os.getenv('ARK_API_KEY')
                if single_key:
                    self.api_keys = [single_key]
        else:
            # å…¶ä»–APIä½¿ç”¨å•å¯†é’¥
            api_key_env = model_info.get('api_key_env')
            if api_key_env:
                key_value = os.getenv(api_key_env) or config.openai_api_key or ""
                if key_value:
                    self.api_keys = [key_value]
                else:
                    self.api_keys = []
            else:
                self.api_keys = [config.openai_api_key] if config.openai_api_key else []
        
        if not self.api_keys:
            raise ValueError("è¯·è®¾ç½®APIå¯†é’¥")
        
        print(f"åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨APIå¯†é’¥æ•°é‡: {len(self.api_keys)}")
    
    def _get_next_api_key(self):
        """è·å–ä¸‹ä¸€ä¸ªAPIå¯†é’¥ï¼ˆè½®è¯¢ï¼‰"""
        if not self.api_keys:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥")
        
        key = self.api_keys[self._current_key_index]
        self._current_key_index = (self._current_key_index + 1) % len(self.api_keys)
        return key
    
    def split_text_to_pages(self, user_text: str, target_pages: Optional[int] = None) -> Dict[str, Any]:
        """
        å°†ç”¨æˆ·æ–‡æœ¬æ™ºèƒ½åˆ†å‰²ä¸ºå¤šä¸ªPPTé¡µé¢
        
        Args:
            user_text: ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ–‡æœ¬
            target_pages: ç›®æ ‡é¡µé¢æ•°é‡ï¼ˆå¯é€‰ï¼Œç”±AIè‡ªåŠ¨åˆ¤æ–­ï¼‰
            
        Returns:
            Dict: åˆ†é¡µç»“æœï¼ŒåŒ…å«æ¯é¡µçš„å†…å®¹å’Œåˆ†æ
        """
        log_user_action("AIæ™ºèƒ½åˆ†é¡µ", f"æ–‡æœ¬é•¿åº¦: {len(user_text)}")
        
        try:
            # æ„å»ºAIæç¤º
            system_prompt = self._build_system_prompt(target_pages)
            
            # æ£€æŸ¥APIç±»å‹ï¼Œå†³å®šè°ƒç”¨æ–¹å¼
            model_info = self.config.get_model_info()
            if model_info.get('request_format') == 'dify_compatible':
                # ä½¿ç”¨Liai APIæ ¼å¼
                content = self._call_liai_api(system_prompt, user_text)
            elif model_info.get('request_format') == 'streaming_compatible':
                # ä½¿ç”¨OpenRouter APIæ ¼å¼ï¼ˆç±»ä¼¼Liaiçš„åˆ†æ‰¹å¤„ç†ï¼‰
                content = self._call_openrouter_api(system_prompt, user_text)
            elif model_info.get('request_format') == 'openai_responses_api':
                # ä½¿ç”¨GPT-5 Responses APIæ ¼å¼
                content = self._call_gpt5_responses_api(system_prompt, user_text)
            else:
                # æ ‡å‡†OpenAI APIæ ¼å¼
                request_timeout = 60
                actual_model = model_info.get('actual_model', self.config.ai_model)
                
                response = self.client.chat.completions.create(
                    model=actual_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_text}
                    ],
                    temperature=0.3,
                    max_tokens=4000,
                    stream=True,
                    timeout=request_timeout
                )
                
                # æ”¶é›†æµå¼å“åº”å†…å®¹
                content = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content += chunk.choices[0].delta.content
                
                content = content.strip() if content else ""
            
            # è§£æAIè¿”å›çš„ç»“æœ
            return self._parse_ai_response(content, user_text)
            
        except Exception as e:
            print(f"AIåˆ†é¡µåˆ†æå¤±è´¥: {e}")
            raise e
    
    def _call_liai_api(self, system_prompt: str, user_text: str) -> str:
        """è°ƒç”¨Liai API"""
        model_info = self.config.get_model_info()
        base_url = model_info.get('base_url', '')
        endpoint = model_info.get('chat_endpoint', '/chat-messages')
        
        url = base_url + endpoint
        
        # æ„å»ºLiai APIè¯·æ±‚æ ¼å¼
        combined_query = f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_text}"
        
        payload = {
            "inputs": {},
            "query": combined_query,
            "response_mode": "streaming",  # æ”¹ä¸ºstreamingæ¨¡å¼æå‡å“åº”é€Ÿåº¦
            "conversation_id": "",
            "user": "ai-ppt-user",
            "files": []
        }
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json',
            'Connection': 'keep-alive'  # ä¿æŒè¿æ¥
        }
        
        try:
            # ä½¿ç”¨æŒä¹…åŒ–ä¼šè¯å¤ç”¨è¿æ¥ï¼Œå¢åŠ è¶…æ—¶å¤„ç†
            response = self.session.post(url, headers=headers, json=payload, timeout=120, stream=True)
            response.raise_for_status()
            
            # å¤„ç†streamingå“åº”ï¼Œç‰¹åˆ«å¤„ç†é˜¿é‡Œäº‘APIçš„keep-alive
            content = ""
            for line in response.iter_lines():
                if line:
                    try:
                        line_text = line.decode('utf-8').strip()
                        # å¿½ç•¥é˜¿é‡Œäº‘çš„keep-aliveæ³¨é‡Š
                        if line_text == ': keep-alive' or line_text == '':
                            continue
                        if line_text.startswith('data: '):
                            json_str = line_text[6:]  # å»æ‰'data: 'å‰ç¼€
                            if json_str.strip() == '[DONE]':
                                break
                            data = json.loads(json_str)
                            if 'answer' in data:
                                content += data['answer']
                            elif 'data' in data and 'answer' in data['data']:
                                content += data['data']['answer']
                    except (json.JSONDecodeError, UnicodeDecodeError):
                        continue
            
            # å¦‚æœstreamingå¤±è´¥ï¼Œå°è¯•ä½œä¸ºæ™®é€šJSONå¤„ç†
            if not content:
                try:
                    result = response.json()
                    content = result.get('answer', '') or result.get('data', {}).get('answer', '')
                except:
                    pass
            
            return content.strip() if content else ""
            
        except Exception as e:
            print(f"Liai APIè°ƒç”¨å¤±è´¥: {e}")
            raise e
    
    def _call_openrouter_api(self, system_prompt: str, user_text: str) -> str:
        """è°ƒç”¨OpenRouter APIï¼ˆå¸¦æ•…éšœè½¬ç§»çš„å¤šå¯†é’¥è´Ÿè½½å‡è¡¡ï¼‰"""
        model_info = self.config.get_model_info()
        
        # è·å–å®é™…æ¨¡å‹åç§°å’Œé¢å¤–å¤´éƒ¨
        actual_model = model_info.get('actual_model', 'openai/gpt-5')
        extra_headers = model_info.get('extra_headers', {})
        
        # å°è¯•æ‰€æœ‰å¯ç”¨å¯†é’¥
        last_exception = None
        for attempt in range(len(self.api_keys)):
            current_api_key = self._get_next_api_key()
            
            try:
                # ä¸ºå½“å‰å¯†é’¥åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
                temp_client = OpenAI(
                    api_key=current_api_key,
                    base_url=self.base_url,
                    timeout=120
                )
                
                print(f"å°è¯•ä½¿ç”¨APIå¯†é’¥ {attempt + 1}/{len(self.api_keys)} (æœ«å°¾: ...{current_api_key[-8:]})")
                
                # ä½¿ç”¨æŒä¹…åŒ–ä¼šè¯å¤ç”¨è¿æ¥ï¼Œç±»ä¼¼Liaiçš„å¤„ç†æ–¹å¼
                response = temp_client.chat.completions.create(
                    model=actual_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_text}
                    ],
                    temperature=0.3,
                    max_tokens=4000,
                    stream=True,  # ä½¿ç”¨æµå¼å“åº”ï¼Œç±»ä¼¼Liai
                    extra_headers=extra_headers,
                    extra_body={},  # OpenRouterå…¼å®¹
                    timeout=120  # ä¸Liaiç›¸åŒçš„è¶…æ—¶æ—¶é—´
                )
                
                # å¤„ç†streamingå“åº”ï¼Œç±»ä¼¼Liaiçš„é€è¡Œå¤„ç†
                content = ""
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                        chunk_content = chunk.choices[0].delta.content
                        if chunk_content:
                            content += chunk_content
                
                result_content = content.strip() if content else ""
                print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œä½¿ç”¨å¯†é’¥: ...{current_api_key[-8:]}")
                return result_content
                
            except Exception as e:
                last_exception = e
                print(f"âŒ APIå¯†é’¥ ...{current_api_key[-8:]} è°ƒç”¨å¤±è´¥: {e}")
                
                # å¦‚æœè¿˜æœ‰å…¶ä»–å¯†é’¥å¯ä»¥å°è¯•ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                if attempt < len(self.api_keys) - 1:
                    print(f"â³ å°è¯•ä¸‹ä¸€ä¸ªAPIå¯†é’¥...")
                    continue
        
        # æ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥äº†
        print(f"âŒ æ‰€æœ‰{len(self.api_keys)}ä¸ªOpenRouter APIå¯†é’¥éƒ½å¤±è´¥äº†")
        raise last_exception or Exception("æ‰€æœ‰OpenRouter APIå¯†é’¥è°ƒç”¨å¤±è´¥")
    
    def _call_gpt5_responses_api(self, system_prompt: str, user_text: str) -> str:
        """è°ƒç”¨GPT-5 Responses APIè¿›è¡Œæ–‡æœ¬åˆ†æ"""
        from openai import OpenAI
        
        client = OpenAI(
            api_key="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"
        )
        
        # ç»„åˆç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æ–‡æœ¬
        full_input = f"{system_prompt}\n\nç”¨æˆ·æ–‡æœ¬ï¼š\n{user_text}"
        
        response = client.responses.create(
            model="gpt-5",
            input=full_input,
            store=True
        )
        
        return response.output_text
    
    def _build_system_prompt(self, target_pages: Optional[int] = None) -> str:
        """æ„å»ºAIç³»ç»Ÿæç¤º"""
        target_instruction = ""
        if target_pages:
            target_instruction = f"ç›®æ ‡åˆ†ä¸º{target_pages}é¡µï¼Œ"
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PPTå†…å®¹åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„æ–‡æœ¬å†…å®¹æ™ºèƒ½åˆ†å‰²ä¸ºé€‚åˆPPTå±•ç¤ºçš„å¤šä¸ªé¡µé¢ã€‚

**æ ¸å¿ƒåŸåˆ™ï¼š**
1. **é€»è¾‘ç»“æ„ä¼˜å…ˆ**ï¼šæŒ‰å†…å®¹çš„é€»è¾‘ä¸»é¢˜åˆ†é¡µï¼ŒåŒä¸€ä¸»é¢˜å’Œç›¸å…³ä¸»é¢˜å¿…é¡»åˆå¹¶
2. **å†…å®¹å……å®æ€§**ï¼šæ¯é¡µå¿…é¡»æœ‰è¶³å¤Ÿå†…å®¹é‡ï¼Œä¸¥ç¦è–„é¡µé¢ï¼ŒAIå€¾å‘è¿‡åº¦åˆ†é¡µéœ€ä¸»åŠ¨æŠµåˆ¶
3. **å¼ºåˆ¶åˆå¹¶ç­–ç•¥**ï¼šç›¸ä¼¼ã€ç›¸å…³ã€å…³è”ä¸»é¢˜å¿…é¡»åˆå¹¶ï¼Œåªæœ‰å®Œå…¨ä¸åŒä¸»é¢˜æ‰åˆ†é¡µ
4. **ä¿¡æ¯å®Œæ•´æ€§**ï¼šä¸é—æ¼é‡è¦ä¿¡æ¯ï¼Œä¿æŒé€»è¾‘å®Œæ•´

**åˆ†é¡µç­–ç•¥ï¼š**
- **æ ‡é¢˜é¡µï¼ˆç¬¬1é¡µï¼‰**ï¼šä»…æå–æ–‡æ¡£æ ‡é¢˜å’Œæ—¥æœŸä¿¡æ¯ï¼Œå…¶ä»–æ‰€æœ‰æ–‡æœ¬å†…å®¹éƒ½å»¶ååˆ°ç¬¬ä¸‰é¡µå¼€å§‹å¤„ç†
- **ç›®å½•é¡µï¼ˆç¬¬2é¡µï¼‰**ï¼šAIå¿…é¡»ç”Ÿæˆå®Œæ•´çš„ç›®å½•å†…å®¹ï¼ŒåŒ…æ‹¬å„ç« èŠ‚æ ‡é¢˜ï¼Œæ ¼å¼å¦‚"ç¬¬ä¸€ç« èŠ‚\nç¬¬äºŒç« èŠ‚\nç¬¬ä¸‰ç« èŠ‚"
- **å†…å®¹é¡µï¼ˆç¬¬3é¡µå¼€å§‹ï¼‰**ï¼šä»ç¬¬ä¸‰é¡µå¼€å§‹å¤„ç†æ‰€æœ‰å®é™…å†…å®¹ï¼ŒæŒ‰ä¸»è¦è§‚ç‚¹ã€æ—¶é—´é¡ºåºæˆ–é€»è¾‘ç»“æ„åˆ†é¡µ
- **ç»“å°¾é¡µ**ï¼šä¸ç”Ÿæˆç»“å°¾é¡µï¼ˆä½¿ç”¨é¢„è®¾çš„å›ºå®šç»“å°¾é¡µæ¨¡æ¿ï¼‰

**æ ‡é¢˜é¡µå¤„ç†è§„åˆ™ï¼š**
- åªä»æ–‡æœ¬å¼€å¤´æå–æ ‡é¢˜ä¿¡æ¯ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€è¡Œæˆ–æœ€é†’ç›®çš„æ–‡å­—ï¼‰
- è‡ªåŠ¨ç”Ÿæˆæˆ–æå–æ—¥æœŸä¿¡æ¯
- å…¶ä½™æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ˆåŒ…æ‹¬å‰¯æ ‡é¢˜ã€ç®€ä»‹ã€æ­£æ–‡ç­‰ï¼‰éƒ½ä¿ç•™ç»™åç»­å†…å®¹é¡µå¤„ç†
- æ ‡é¢˜é¡µçš„original_text_segmentåªåŒ…å«æå–çš„æ ‡é¢˜éƒ¨åˆ†

**é¡µé¢å†…å®¹è¦æ±‚ï¼š**
- æ¯é¡µåº”è¯¥æœ‰æ¸…æ™°çš„**ä¸»é¢˜**ï¼ˆé€šè¿‡titleå­—æ®µä½“ç°ï¼‰
- **ä¼˜å…ˆæŒ‰é€»è¾‘åˆ†é…**ï¼šå±äºåŒä¸€ä¸ªä¸»é¢˜ã€æ¦‚å¿µæˆ–ç« èŠ‚çš„å†…å®¹åº”è¯¥æ”¾åœ¨åŒä¸€é¡µ
- **é‡ç‚¹ä¿ç•™åŸæ–‡**ï¼šoriginal_text_segmentå­—æ®µå¿…é¡»åŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´åŸæ–‡ç‰‡æ®µ
- **å†…å®¹é‡ä¼˜å…ˆçº§**ï¼šé€‚ä¸­ >> è¿‡å¤š >> è¿‡å°‘ï¼ˆå®å¯å†…å®¹å¤šä¸€äº›ï¼Œä¹Ÿä¸è¦è®©é¡µé¢æ˜¾å¾—ç©ºæ´ï¼‰
- ä¿æŒå†…å®¹çš„**è¿è´¯æ€§**å’Œ**å®Œæ•´æ€§**

**åˆ†é¡µå»ºè®®ï¼ˆæç®€ç­–ç•¥ - æœ€å¤§åŒ–å†…å®¹åˆå¹¶ï¼‰ï¼š**
- æçŸ­æ–‡æœ¬ï¼ˆ<300å­—ï¼‰ï¼šä»…1é¡µå†…å®¹ï¼ˆå…¨éƒ¨å†…å®¹æ”¾åœ¨ä¸€é¡µï¼‰
- çŸ­æ–‡æœ¬ï¼ˆ300-1000å­—ï¼‰ï¼š1é¡µå†…å®¹ï¼ˆå¼ºåˆ¶åˆå¹¶ä¸º1é¡µï¼‰
- ä¸­ç­‰æ–‡æœ¬ï¼ˆ1000-2000å­—ï¼‰ï¼š1-2é¡µå†…å®¹ï¼ˆä¼˜å…ˆåˆå¹¶ä¸º1é¡µï¼Œä»…åœ¨é€»è¾‘å®Œå…¨ä¸ç›¸å…³æ—¶åˆ†ä¸º2é¡µï¼‰
- é•¿æ–‡æœ¬ï¼ˆ2000-4000å­—ï¼‰ï¼š2-3é¡µå†…å®¹ï¼ˆæŒ‰ä¸»è¦ç« èŠ‚åˆ†é¡µï¼Œå¤§é‡åˆå¹¶å°èŠ‚ï¼‰
- è¶…é•¿æ–‡æœ¬ï¼ˆ>4000å­—ï¼‰ï¼š3-6é¡µå†…å®¹ï¼ˆä»…æŒ‰ä¸»è¦ç« èŠ‚åˆ†é¡µï¼Œä¸¥æ ¼åˆå¹¶å­ä¸»é¢˜ï¼‰
- **æ ¸å¿ƒåŸåˆ™ï¼šèƒ½åˆå¹¶å¿…é¡»åˆå¹¶ï¼Œå®å¯å•é¡µå†…å®¹ä¸°å¯Œä¹Ÿä¸è¦é¡µé¢åˆ†æ•£**
- **æœ€å°é˜ˆå€¼ï¼šæ¯é¡µè‡³å°‘300å­—ï¼Œä½äºæ­¤é˜ˆå€¼å¿…é¡»ä¸ç›¸é‚»é¡µé¢åˆå¹¶**

{target_instruction}è¯·åˆ†æç”¨æˆ·æ–‡æœ¬çš„ç»“æ„å’Œå†…å®¹ï¼ŒæŒ‰é€»è¾‘ä¸»é¢˜æ™ºèƒ½åˆ†å‰²ä¸ºåˆé€‚çš„é¡µé¢æ•°é‡ã€‚

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

```json
{{{{
  "analysis": {{{{
    "total_pages": 4,
    "content_type": "æŠ€æœ¯ä»‹ç»",
    "split_strategy": "æŒ‰å‘å±•é˜¶æ®µåˆ†é¡µ",
    "reasoning": "æ–‡æœ¬æè¿°äº†æŠ€æœ¯å‘å±•çš„å¤šä¸ªé˜¶æ®µï¼Œé€‚åˆæŒ‰æ—¶é—´çº¿åˆ†é¡µå±•ç¤º"
  }}}},
  "pages": [
    {{{{
      "page_number": 1,
      "page_type": "title",
      "title": "äººå·¥æ™ºèƒ½å‘å±•å†ç¨‹",
      "date": "2024å¹´7æœˆ",
      "original_text_segment": "äººå·¥æ™ºèƒ½å‘å±•å†ç¨‹"
    }}}},
    {{{{
      "page_number": 2,
      "page_type": "table_of_contents",
      "title": "ç›®å½•",
      "original_text_segment": "AIå‘å±•æ¦‚è¿°\næŠ€æœ¯çªç ´é˜¶æ®µ\nå½“å‰å‘å±•è¶‹åŠ¿\næœªæ¥å±•æœ›"
    }}}},
    {{{{
      "page_number": 3,
      "page_type": "content", 
      "title": "AIå‘å±•æ¦‚è¿°",
      "original_text_segment": "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•ç»å†äº†å¤šä¸ªé‡è¦é˜¶æ®µã€‚ä»1950å¹´ä»£çš„ç¬¦å·ä¸»ä¹‰å¼€å§‹ï¼Œåˆ°1980å¹´ä»£ä¸“å®¶ç³»ç»Ÿçš„å…´èµ·ï¼Œå†åˆ°2010å¹´ä»£æ·±åº¦å­¦ä¹ çš„çªç ´ï¼Œä»¥åŠå½“å‰å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„åˆ°æ¥..."
    }}}}
  ]
}}}}
```

**é¡µé¢ç±»å‹è¯´æ˜ï¼š**
- `title`: æ ‡é¢˜é¡µï¼Œä»…åŒ…å«æ–‡æ¡£æ ‡é¢˜å’Œæ—¥æœŸ
- `table_of_contents`: ç›®å½•é¡µï¼Œå¿…é¡»åŒ…å«å„ç« èŠ‚æ ‡é¢˜ï¼ˆä¸å«é¡µç ï¼‰
- `content`: å†…å®¹é¡µï¼Œå…·ä½“çš„è¦ç‚¹å’Œè¯¦ç»†å†…å®¹ï¼ˆåˆ†é¡µé‡ç‚¹ï¼‰

**å…³é”®æ³¨æ„äº‹é¡¹ï¼š**
- **titleå­—æ®µ**ï¼šå¿…é¡»å‡†ç¡®æ¦‚æ‹¬è¯¥é¡µå†…å®¹ï¼ˆç”¨äºç”Ÿæˆç›®å½•ï¼‰
- **original_text_segmentå­—æ®µæœ€é‡è¦**ï¼šå¿…é¡»åŒ…å«è¯¥é¡µå¯¹åº”çš„å®Œæ•´åŸæ–‡ç‰‡æ®µï¼Œä¸èƒ½é—æ¼æˆ–æˆªæ–­
- **æ ‡é¢˜é¡µoriginal_text_segment**ï¼šåªåŒ…å«æå–çš„æ ‡é¢˜éƒ¨åˆ†
- **ç›®å½•é¡µoriginal_text_segment**ï¼šåŒ…å«å„ç« èŠ‚æ ‡é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡é¢˜
- **å†…å®¹é¡µoriginal_text_segment**ï¼šåŒ…å«è¯¥é¡µé¢å¯¹åº”çš„æ‰€æœ‰åŸæ–‡å†…å®¹ï¼Œç¡®ä¿å®Œæ•´æ€§
- ä¸è¦ç”Ÿæˆç»“å°¾é¡µï¼Œç³»ç»Ÿå°†ä½¿ç”¨é¢„è®¾çš„å›ºå®šç»“å°¾é¡µæ¨¡æ¿

åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
    
    def _parse_ai_response(self, content: str, user_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº”ç»“æœ"""
        try:
            # æ£€æŸ¥è¿”å›å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content or not content.strip():
                error_detail = f"AIè¿”å›å†…å®¹ä¸ºç©ºã€‚åŸå§‹å†…å®¹: '{content}'"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            
            # æå–JSONå†…å®¹
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
                json_str = content.strip()
            
            if not json_str or not json_str.strip():
                error_detail = "æå–çš„JSONå­—ç¬¦ä¸²ä¸ºç©º"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            # è§£æJSON
            result = json.loads(json_str)
            
            # éªŒè¯ç»“æœæ ¼å¼
            if not self._validate_split_result(result):
                error_detail = "AIè¿”å›çš„JSONæ ¼å¼ä¸ç¬¦åˆè¦æ±‚"
                print(f"âŒ {error_detail}")
                raise ValueError(error_detail)
            
            result['success'] = True
            result['original_text'] = user_text
            
            # æ·»åŠ å›ºå®šçš„ç»“å°¾é¡µ
            self._add_ending_page(result)
            
            return result
                
        except json.JSONDecodeError as e:
            json_str_safe = json_str[:500] if 'json_str' in locals() else 'æœªè·å–åˆ°'
            error_msg = f"JSONè§£æå¤±è´¥: {e}\nå°è¯•è§£æçš„å†…å®¹: {json_str_safe}"
            print(f"âŒ {error_msg}")
            
            
            raise ValueError(error_msg)
        except Exception as e:
            content_safe = content[:500] if content else 'N/A'
            error_msg = f"AIåˆ†é¡µè§£æå¤±è´¥: {e}\nåŸå§‹AIè¿”å›å†…å®¹: {content_safe}..."
            print(f"âŒ {error_msg}")
            
            
            raise e
    
    def _validate_split_result(self, result: Dict[str, Any]) -> bool:
        """éªŒè¯åˆ†é¡µç»“æœçš„æ ¼å¼"""
        try:
            # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
            if 'analysis' not in result or 'pages' not in result:
                return False
            
            analysis = result['analysis']
            pages = result['pages']
            
            # æ£€æŸ¥analysiså­—æ®µ
            required_analysis_fields = ['total_pages', 'content_type', 'split_strategy']
            for field in required_analysis_fields:
                if field not in analysis:
                    return False
            
            # æ£€æŸ¥pagesæ•°ç»„
            if not isinstance(pages, list) or len(pages) == 0:
                return False
            
            # æ£€æŸ¥æ¯ä¸ªé¡µé¢çš„å­—æ®µ
            required_page_fields = ['page_number', 'page_type', 'title', 'original_text_segment']
            for page in pages:
                for field in required_page_fields:
                    if field not in page:
                        return False
                
                # æ£€æŸ¥original_text_segmentæ˜¯å­—ç¬¦ä¸²
                if not isinstance(page['original_text_segment'], str):
                    return False
            
            return True
            
        except Exception:
            return False
    
    def _create_fallback_split(self, user_text: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨åˆ†é¡µæ–¹æ¡ˆ"""
        # æŒ‰è¡Œåˆ†å‰²ï¼Œæ‰¾åˆ°æ ‡é¢˜
        lines = [line.strip() for line in user_text.split('\n') if line.strip()]
        if not lines:
            lines = [user_text.strip()]
        
        # æå–æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€è¡Œï¼Œä¸”ç›¸å¯¹è¾ƒçŸ­ï¼‰
        title = lines[0] if lines else "å†…å®¹å±•ç¤º"
        if len(title) > 50:  # å¦‚æœç¬¬ä¸€è¡Œå¤ªé•¿ï¼Œå¯èƒ½ä¸æ˜¯æ ‡é¢˜ï¼Œæˆªå–å‰é¢éƒ¨åˆ†
            title = title[:30] + "..."
        
        pages = []
        
        # åˆ›å»ºæ ‡é¢˜é¡µï¼ˆä»…åŒ…å«ä»æ–‡æœ¬å¼€å¤´æå–çš„æ ‡é¢˜å’Œæ—¥æœŸï¼‰
        import datetime
        current_date = datetime.datetime.now().strftime("%Yå¹´%mæœˆ")
        
        pages.append({
            "page_number": 1,
            "page_type": "title", 
            "title": title,
            "date": current_date,
            "original_text_segment": title  # åªåŒ…å«æ ‡é¢˜éƒ¨åˆ†
        })
        
        # å°†é™¤æ ‡é¢˜å¤–çš„æ‰€æœ‰å†…å®¹åˆ†é…åˆ°ç¬¬3é¡µå¼€å§‹çš„å†…å®¹é¡µï¼ˆç¬¬2é¡µæ˜¯å›ºå®šç›®å½•é¡µï¼‰
        # é‡æ–°ç»„ç»‡å†…å®¹ï¼šå»æ‰æ ‡é¢˜è¡Œåçš„æ‰€æœ‰æ–‡æœ¬
        remaining_text = user_text
        if lines and len(lines) > 1:
            # å»æ‰ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜ï¼‰ï¼Œä¿ç•™å…¶ä½™å†…å®¹
            title_end_pos = user_text.find(lines[0]) + len(lines[0])
            remaining_text = user_text[title_end_pos:].strip()
        
        # æŒ‰æ®µè½åˆ†å‰²å‰©ä½™å†…å®¹
        remaining_paragraphs = [p.strip() for p in remaining_text.split('\n\n') if p.strip()]
        if not remaining_paragraphs and remaining_text:
            remaining_paragraphs = [remaining_text]
        
        page_num = 3  # ä»ç¬¬3é¡µå¼€å§‹ï¼ˆç¬¬2é¡µæ˜¯å›ºå®šç›®å½•é¡µï¼‰
        if remaining_paragraphs:
            for i, paragraph in enumerate(remaining_paragraphs):
                # é™åˆ¶æ€»é¡µæ•°ä¸è¶…è¿‡23é¡µï¼ˆä¸ºç›®å½•é¡µå’Œç»“å°¾é¡µé¢„ç•™ç©ºé—´ï¼‰
                if page_num > 23:
                    print(f"è­¦å‘Šï¼šå†…å®¹è¿‡å¤šï¼Œå·²è¾¾åˆ°23é¡µä¸Šé™ï¼Œå‰©ä½™{len(remaining_paragraphs) - i}æ®µå†…å®¹å°†è¢«çœç•¥")
                    break
                    
                pages.append({
                    "page_number": page_num,
                    "page_type": "content",
                    "title": f"å†…å®¹ {page_num - 2}",
                    "original_text_segment": paragraph
                })
                page_num += 1
        else:
            # å¦‚æœæ²¡æœ‰å‰©ä½™å†…å®¹ï¼Œè‡³å°‘åˆ›å»ºä¸€ä¸ªç©ºçš„å†…å®¹é¡µ
            pages.append({
                "page_number": 3,
                "page_type": "content",
                "title": "å†…å®¹é¡µ",
                "original_text_segment": "æ— é¢å¤–å†…å®¹"
            })
        
        result = {
            "success": True,
            "analysis": {
                "total_pages": len(pages),
                "content_type": "é€šç”¨å†…å®¹",
                "split_strategy": "æŒ‰æ®µè½åˆ†é¡µ",
                "reasoning": "é‡‡ç”¨å¤‡ç”¨åˆ†é¡µç­–ç•¥ï¼ŒæŒ‰æ®µè½è‡ªåŠ¨åˆ†å‰²"
            },
            "pages": pages,
            "original_text": user_text,
            "is_fallback": True
        }
        
        # æ·»åŠ å›ºå®šçš„ç›®å½•é¡µå’Œç»“å°¾é¡µ
        self._add_table_of_contents_page(result)
        self._add_ending_page(result)
        
        return result
    
    def _add_table_of_contents_page(self, result: Dict[str, Any]) -> None:
        """æ·»åŠ åŠ¨æ€ç›®å½•é¡µï¼ˆç¬¬2é¡µï¼‰"""
        import os
        
        pages = result.get('pages', [])
        if not pages:
            return
        
        # è°ƒæ•´ç°æœ‰é¡µé¢çš„é¡µç ï¼ˆä¸ºç›®å½•é¡µè…¾å‡ºç¬¬2é¡µä½ç½®ï¼‰
        for page in pages:
            if page.get('page_number', 1) > 1:
                page['page_number'] = page['page_number'] + 1
        
        # æå–æ‰€æœ‰å†…å®¹é¡µçš„æ ‡é¢˜ä¿¡æ¯ï¼Œç”ŸæˆåŠ¨æ€ç›®å½•
        content_titles = []
        for page in pages:
            if page.get('page_type') == 'content' and page.get('title'):
                page_number = page.get('page_number', 0)
                title = page.get('title', '').strip()
                subtitle = page.get('subtitle', '').strip()
                
                # æ„å»ºç›®å½•é¡¹
                if subtitle:
                    toc_item = f"{page_number}. {title} - {subtitle}"
                else:
                    toc_item = f"{page_number}. {title}"
                content_titles.append(toc_item)
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤ç›®å½•
        if not content_titles:
            content_titles = [
                "æ¼”ç¤ºå†…å®¹å¯¼èˆª",
                "ç« èŠ‚ç»“æ„é¢„è§ˆ"
            ]
        
        # åˆ›å»ºåŠ¨æ€ç›®å½•é¡µä¿¡æ¯
        table_of_contents_page = {
            "page_number": 2,
            "page_type": "table_of_contents",
            "title": "ç›®å½•",
            "original_text_segment": "",
            "template_path": os.path.join("templates", "table_of_contents_slides.pptx"),
            "is_toc_page": True,  # æ ‡è®°ä¸ºç›®å½•é¡µ
            "skip_dify_api": True,  # ä¸éœ€è¦è°ƒç”¨Dify APIï¼Œä½†å†…å®¹å·²åŠ¨æ€æå–
            "toc_items": content_titles  # å°†ç›®å½•é¡¹å•ç‹¬å­˜å‚¨
        }
        
        # å°†ç›®å½•é¡µæ’å…¥åˆ°ç¬¬2ä½
        pages.insert(1, table_of_contents_page)
        
        # æ›´æ–°åˆ†æä¿¡æ¯ä¸­çš„æ€»é¡µæ•°
        if 'analysis' in result:
            result['analysis']['total_pages'] = len(pages)
    
    def _add_ending_page(self, result: Dict[str, Any]) -> None:
        """æ·»åŠ å›ºå®šçš„ç»“å°¾é¡µ"""
        import os
        
        pages = result.get('pages', [])
        if not pages:
            return
        
        # è®¡ç®—ç»“å°¾é¡µçš„é¡µç 
        ending_page_number = len(pages) + 1
        
        # æ·»åŠ ç»“å°¾é¡µä¿¡æ¯
        ending_page = {
            "page_number": ending_page_number,
            "page_type": "ending",
            "title": "è°¢è°¢è§‚çœ‹",
            "original_text_segment": "",
            "template_path": os.path.join("templates", "ending_slides.pptx"),
            "is_fixed_template": True,
            "skip_dify_api": True  # æ ‡è®°ä¸ºè·³è¿‡Dify APIè°ƒç”¨
        }
        
        pages.append(ending_page)
        
        # æ›´æ–°æ€»é¡µæ•°
        if 'analysis' in result:
            result['analysis']['total_pages'] = len(pages)

class PageContentFormatter:
    """é¡µé¢å†…å®¹æ ¼å¼åŒ–å·¥å…·"""
    
    @staticmethod
    def format_page_preview(page: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–é¡µé¢é¢„è§ˆæ–‡æœ¬"""
        page_type_map = {
            "title": "ğŸ·ï¸ æ ‡é¢˜é¡µ",
            "overview": "ğŸ“‹ æ¦‚è¿°é¡µ",
            "table_of_contents": "ğŸ“‘ ç›®å½•é¡µ", 
            "content": "ğŸ“„ å†…å®¹é¡µ",
            "ending": "ğŸ”š ç»“æŸé¡µ"
        }
        
        page_type_display = page_type_map.get(page.get('page_type', 'content'), "ğŸ“„ å†…å®¹é¡µ")
        
        preview = f"**{page_type_display} - ç¬¬{page.get('page_number', 1)}é¡µ**\n\n"
        preview += f"**æ ‡é¢˜ï¼š** {page.get('title', 'æœªè®¾ç½®æ ‡é¢˜')}\n"
        
        # æ ‡é¢˜é¡µç‰¹æ®Šå¤„ç†
        if page.get('page_type') == 'title':
            if page.get('date'):
                preview += f"**æ—¥æœŸï¼š** {page.get('date')}\n"
            preview += f"**è¯´æ˜ï¼š** æ ‡é¢˜é¡µä½¿ç”¨å›ºå®šæ¨¡æ¿ï¼Œå…¶ä»–å†…å®¹ï¼ˆä½œè€…ã€æœºæ„ç­‰ï¼‰å°†è‡ªåŠ¨å¡«å……\n\n"
        
        # æ˜¾ç¤ºåŸæ–‡ç‰‡æ®µ
        original_text = page.get('original_text_segment', '')
        if original_text and original_text.strip():
            preview += "**åŸæ–‡å†…å®¹ï¼š**\n"
            # å¦‚æœåŸæ–‡å¤ªé•¿ï¼Œæ˜¾ç¤ºå‰200å­—ç¬¦
            if len(original_text) > 200:
                preview += f"{original_text[:200]}...\n"
            else:
                preview += f"{original_text}\n"
        
        return preview
    
    @staticmethod
    def format_analysis_summary(analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åˆ†ææ‘˜è¦"""
        summary = f"**ğŸ“Š åˆ†é¡µåˆ†æç»“æœ**\n\n"
        summary += f"â€¢ **æ€»é¡µæ•°ï¼š** {analysis.get('total_pages', 0)} é¡µ\n"
        summary += f"â€¢ **å†…å®¹ç±»å‹ï¼š** {analysis.get('content_type', 'æœªçŸ¥')}\n"
        summary += f"â€¢ **åˆ†é¡µç­–ç•¥ï¼š** {analysis.get('split_strategy', 'æœªçŸ¥')}\n"
        
        if analysis.get('reasoning'):
            summary += f"â€¢ **åˆ†æè¯´æ˜ï¼š** {analysis.get('reasoning')}\n"
        
        return summary 